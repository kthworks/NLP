{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b71c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6e6938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : Hyunjoong Kim lovit@github\n",
      "    Repository : https://github.com/lovit/petitions_archive\n",
      "    References :\n",
      "\n",
      "    청와대 국민청원 게시판의 데이터를 월별로 수집한 것입니다.\n",
      "    청원은 게시판에 글을 올린 뒤, 한달 간 청원이 진행됩니다.\n",
      "    수집되는 데이터는 청원종료가 된 이후의 데이터이며, 청원 내 댓글은 수집되지 않습니다.\n",
      "    단 청원의 동의 개수는 수집됩니다.\n",
      "    자세한 내용은 위의 repository를 참고하세요.\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2017-08\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2017-09\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2017-10\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2017-11\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2017-12\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-01\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-02\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-03\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-04\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-05\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-06\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-07\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-08\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-09\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-10\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-11\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2018-12\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2019-01\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2019-02\n",
      "[Korpora] Corpus `korean_petitions` is already installed at C:\\Users\\ImedisynRnD2\\Korpora\\korean_petitions\\petitions_2019-03\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "corpus = Korpora.load(\"korean_petitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8673b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = corpus.train.texts\n",
    "\n",
    "text = []\n",
    "for i in range(100):              # 게시글 100개만 추출\n",
    "    text.append(all_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5534b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th sentence is spliting...\n",
      "20th sentence is spliting...\n",
      "30th sentence is spliting...\n",
      "40th sentence is spliting...\n",
      "50th sentence is spliting...\n",
      "60th sentence is spliting...\n",
      "70th sentence is spliting...\n",
      "80th sentence is spliting...\n",
      "90th sentence is spliting...\n",
      "100th sentence is spliting...\n"
     ]
    }
   ],
   "source": [
    "import kss\n",
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "class Prep():\n",
    "        \n",
    "    def Clean_text(self, text):\n",
    "\n",
    "        self.sentences = []\n",
    "        \n",
    "        for i in range(len(text)):\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(str(i+1) + 'th sentence is spliting...')\n",
    "        \n",
    "            temp = re.sub(\"[^가-힣a-z0-9.?]\", ' ', text[i]) #한글, 영어, 숫자, 온점, 물음표가 아닌 것을 공백으로 삭제\n",
    "            temp = re.sub(\"[.]{2,}\", \".\", temp) # 반복되는 온점 (...) 삭제\n",
    "            temp = re.sub(\"[?]{2,}\", \"?\", temp) # 반복되는 물음표 (?) 삭제\n",
    "            temp = re.sub(\"[!]{2,}\", \"!\", temp) # 반복되는 느낌표 (!) 삭제\n",
    "            temp = re.sub(\"[' ']{2,}\", \" \", temp) # 반복되는 공백 삭제 \n",
    "            temp = kss.split_sentences(temp)  #문장 분리\n",
    "\n",
    "            for tmp in temp:\n",
    "                self.sentences.append(tmp)\n",
    "        \n",
    "        return self.sentences\n",
    "\n",
    "        \n",
    "    def Tokenizer(self, sentences):\n",
    "        \n",
    "        self.corpus = []\n",
    "        self.words = []\n",
    "        self.vocab = []\n",
    "        \n",
    "        tokenizer = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")\n",
    "        \n",
    "        for sent in self.sentences:\n",
    "            temp = tokenizer.morphs(sent)\n",
    "            self.corpus.append(temp)\n",
    "            \n",
    "            for tmp in temp:\n",
    "                self.words.append(tmp)\n",
    "\n",
    "        self.vocab = set(self.words)\n",
    "        \n",
    "        return self.corpus, self.words, self.vocab\n",
    "    \n",
    "    def Get_clean(self, text):\n",
    "        sentences =  prep.Clean_text(text)\n",
    "        corpus, words, vocab = prep.Tokenizer(self.sentences)\n",
    "        \n",
    "        return sentences, corpus, words, vocab\n",
    "        \n",
    "\n",
    "prep = Prep()\n",
    "sentences, corpus, words, vocab = prep.Get_clean(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c9caf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sentences :  1870\n",
      "# of corpus :  1870\n",
      "# of all words :  50111\n",
      "# of words in vocabulary :  4974\n"
     ]
    }
   ],
   "source": [
    "print('# of sentences : ' , len(sentences)) # 전체 문장 수 확인\n",
    "print('# of corpus : ', len(corpus)) # 전체 corpus 문장 수 확인 (corpus는 각 문장을 형태소단위로 분리해놓은 것)\n",
    "print('# of all words : ' , len(words)) # 전체 단어 수 확인(단어 중복 포함)\n",
    "print('# of words in vocabulary : ' , len(vocab)) # vocabulary 확인 (단어 중복 제거) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f65baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {w: i for i, w in enumerate(vocab)}\n",
    "index_dict = {i: w for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "67f1882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.89228524865535\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "wordFreq = defaultdict(int)\n",
    "\n",
    "for word in words:\n",
    "     wordFreq[word] += 1\n",
    "\n",
    "totalWords = sum([freq**(3/4) for freq in wordFreq.values()])\n",
    "\n",
    "wordProb = {word:(freq/totalWords)**(3/4) for word, freq in wordFreq.items()}\n",
    "\n",
    "# print(wordProb)\n",
    "print(sum(wordProb.values()))\n",
    "\n",
    "# def Negative_sampling(num_samples):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca5aeb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 사대 교대 등 교원양성학교들의 예비교사들이 임용절벽에 매우 힘들어 하고 있는 줄로 압니다.\n",
      "4356\n"
     ]
    }
   ],
   "source": [
    "def Make_in_out_pairs(corpus, win_size, neg_sam_size):\n",
    "    print('Make center word and context words ... ')\n",
    "    \n",
    "    for cor in corpus: # each sentence in corpus\n",
    "        for idx, token in enumerate(cor): # each idx and token in sentence\n",
    "            \n",
    "            center = token[idx]\n",
    "            head = min(0, idx-m)\n",
    "            tail = max(len(token)-1,idx+m)\n",
    "            context = [i for i in range(head,tail+1) if i is not center]\n",
    "            \n",
    "            # Negative sampling\n",
    "            \n",
    "            for i \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Done !')\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6c366f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5]\n"
     ]
    }
   ],
   "source": [
    "head = 4\n",
    "center = 6\n",
    "tail = 6\n",
    "print([i for i in range(head,tail+1) if i is not center])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
